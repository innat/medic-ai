{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#medicai","title":"MedicAI","text":"<p>The <code>medicai</code> is a Keras based library designed for medical image analysis using machine learning techniques. Its core strengths include:</p> <ul> <li>Backend Agnostic: Compatible with <code>tensorflow</code>, <code>torch</code>, and <code>jax</code>.</li> <li>User-Friendly API: High-level interface for transformations and model creation.</li> <li>Scalable Execution: Supports training and inference on single/multi-GPU and TPU-VM setups.</li> <li>Essential Components: Includes standard metrics and losses, such as Dice.</li> <li>Optimized 3D Inference: Offers an efficient sliding-window method and callback for volumetric data</li> </ul>"},{"location":"#installation","title":"\ud83d\udee0 Installation","text":"<p>PyPI version:</p> <pre><code>pip install medicai\n</code></pre> <p>Installing from source GitHub:</p> <pre><code>pip install git+https://github.com/innat/medic-ai.git\n</code></pre>"},{"location":"#available-features","title":"\ud83c\udf41 Available Features","text":"<p>The <code>medicai</code> library provides a range of features for medical image processing, model training, and inference. Below is an overview of its key functionalities.</p> <p>Image Transformations</p> <p><code>medicai</code> includes various transformation utilities for preprocessing medical images:</p> <ul> <li>Basic Transformations:<ul> <li><code>Resize</code>: Adjusts the image dimensions.</li> <li><code>ScaleIntensityRange</code>: Normalizes intensity values within a specified range.</li> <li><code>CropForeground</code>: Crops the image to focus on the region of interest.</li> <li><code>Spacing</code>: Resamples the image to a target voxel spacing.</li> <li><code>Orientation</code>: Standardizes image orientation.</li> <li><code>NormalizeIntensity</code>: Normalize the intensity of tensors based on global or channel-wise statistics.</li> <li><code>SignalFillEmpty</code>: Fills <code>nan</code>, positive infinity, and negative infinity values in specified tensors with a given replacement.</li> </ul> </li> <li>Augmentations for Robustness:<ul> <li><code>RandCropByPosNegLabel</code>: Randomly crops based on positive and negative label ratios.</li> <li><code>RandRotate90</code>: Randomly rotates images by 90 degrees.</li> <li><code>RandShiftIntensity</code>: Randomly shifts intensity values.</li> <li><code>RandFlip</code>: Randomly flips images along specified axes.</li> <li><code>RandomSpatialCrop</code>: Randomly crops a region of interest (ROI).</li> </ul> </li> <li>Pipeline Composition:<ul> <li><code>Compose</code>: Chains multiple transformations into a single pipeline.</li> </ul> </li> </ul> <p>Models</p> <p>Currently, <code>medicai</code> focuses on 3D models for classification and segmentation:</p> <ul> <li><code>SwinTransformer</code> \u2013 3D classification task.</li> <li><code>SwinUNETR</code> \u2013 3D segmentation task.</li> </ul> <p>Inference</p> <ul> <li><code>SlidingWindowInference</code> \u2013 Processes large 3D images in smaller overlapping windows, improving performance and memory efficiency.</li> </ul>"},{"location":"#guides","title":"\ud83d\udca1 Guides","text":"<p>Segmentation: Available guides for 3D segmentation task.</p> Task GitHub Kaggle Covid-19 BTCV BraTS Spleen <p>Classification: Available guides for 3D classification task.</p> Task (Classification) GitHub Kaggle Covid-19"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Please refer to the current roadmap for an overview of the project. Feel free to explore anything that interests you. If you have suggestions or ideas, I\u2019d appreciate it if you could open a GitHub issue so we can discuss them further.</p> <ol> <li>Install <code>medicai</code> from soruce:</li> </ol> <pre><code>!git clone https://github.com/innat/medic-ai\n%cd medic-ai\n!pip install keras -qU\n!pip install -e .\n%cd ..\n</code></pre> <p>Add your contribution and implement relevant test code.</p> <ol> <li>Run test code as:</li> </ol> <pre><code>python -m pytest test/\n\n# or, only one your new_method\npython -m pytest -k new_method\n</code></pre>"},{"location":"#acknowledgements","title":"\ud83d\ude4f Acknowledgements","text":"<p>This project is greatly inspired by MONAI.</p>"},{"location":"#citation","title":"\ud83d\udcdd Citation","text":"<p>If you use <code>medicai</code> in your research or educational purposes, please cite it using the metadata from our <code>CITATION.cff</code> file.</p>"},{"location":"general/","title":"General","text":""},{"location":"general/#generate-3d-nii-to-tfrecord-dataset","title":"Generate 3D <code>.nii</code> to TFRecord Dataset","text":"<ol> <li>Convert COVID-19 CT Segmentation (20 Cases) to TFRecord.</li> <li>Convert Multi-Organ BTCV Abdomen to TFRecord</li> <li>Convert Multi-Modal BraTS to TFRecord</li> </ol>"},{"location":"models/manage-models/","title":"Model","text":"<p>The <code>medicai</code> provides Swin Transformer and SwinUNETR models for 3D classification and segmentation respectively. These models are translated from official release to keras, and able to run on multiple backend, i.e., <code>tensorflow</code>, <code>torch</code>, and, <code>jax</code> backends.</p>"},{"location":"models/manage-models/#3d-models","title":"3D Models","text":"<p>Classification</p> <pre><code>import tensorflow as tf\nfrom medicai.models import SwinTransformer\n\nnum_classes = 4\ninput_shape = (96, 96, 96, 1)\nmodel = SwinTransformer(\n    input_shape=input_shape, \n    num_classes=num_classes, \n    classifier_activation=None\n)\n\ndummy_input = tf.random.normal((1, 96, 96, 96, 1))\noutput = model(dummy_input)\noutput.shape\nTensorShape([1, 4])\n</code></pre> <p>Segmentation</p> <pre><code>import tensorflow as tf\nfrom medicai.models import SwinUNETR\n\nnum_classes = 4\ninput_shape = (96, 96, 96, 1)\nmodel = SwinUNETR(\n    input_shape=input_shape, \n    num_classes=num_classes,\n    classifier_activation=None\n)\n\ndummy_input = tf.random.normal((1, 96, 96, 96, 1))\noutput = model(dummy_input)\noutput.shape\nTensorShape([1, 96, 96, 96, 4])\n</code></pre>"},{"location":"training/manage-training/","title":"Training","text":"<p>The following guides provide comprehensive, end-to-end examples covering data loading, model training, and evaluation workflows. You can use various types of data loaders, including <code>tf.data.Dataset</code>, <code>keras.utils.PyDataset</code>, <code>torch.utils.data.DataLoader</code>, or even a custom Python generator function. These workflows are designed to be flexible and can run seamlessly on a single device or scale across multiple GPUs or TPUs, depending on your setup.</p> <p>Segmentation: Available guides for 3D segmentation task.</p> Task GitHub Kaggle Covid-19 BTCV BraTS Spleen <p>Classification: Available guides for 3D classification task.</p> Task (Classification) GitHub Kaggle Covid-19"},{"location":"transformations/manage-transformations/","title":"Transformation","text":"<p>Transformation acts as a prprocessing and augmentation layers for model training. In <code>medicai</code> for 3D transformation, the expected format is: <code>depth, height, width, channel</code>. The transformation are implemented for a single sample. All the transformations are implemented using <code>tensorflow</code> in order to able to run with <code>tf.data</code> API with <code>keras</code> multi-backend library.</p> <p>Run the following code in kaggle environment: 3D Transformation. It contains side by side comparison between <code>medicai</code> and <code>monai</code>.</p>"},{"location":"transformations/manage-transformations/#load-image","title":"Load Image","text":"<pre><code>def PyLoadImage(image_path, label_path):\n    # load data\n    image_nii = nib.load(image_path)\n    label_nii = nib.load(label_path)\n    image = image_nii.get_fdata().astype(np.float32)\n    label = label_nii.get_fdata().astype(np.float32)\n    affine = np.array(image_nii.affine, dtype=np.float32)\n\n    # re-arrange shape [whd -&gt; dhw]\n    image = np.transpose(image, (2, 1, 0))\n    label = np.transpose(label, (2, 1, 0))\n    affine[:, :3] = affine[:, [2, 1, 0]]\n\n    # add channel axis\n    image = image[..., np.newaxis] if image.ndim == 3 else image\n    label = label[..., np.newaxis] if label.ndim == 3 else label\n\n    # pack to dict\n    data = {}\n    meta = {}\n    data['image'] = image\n    data['label'] = label\n    meta['affine'] = affine\n    return data, meta\n\nimg_path = 'images/coronacases_001.nii.gz'\nmask_path = 'masks/coronacases_001.nii.gz'\n</code></pre>"},{"location":"transformations/manage-transformations/#resize","title":"Resize","text":"<p>Resize the input image to given spatial size. Implemented using <code>tf.image.resize</code> and <code>depth_interpolate</code>.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    Resize,\n)\n\n# define transformations\ntransform = Compose([\n    Resize(\n        keys=[\"image\", \"label\"], \n        spatial_shape=(96, 96, 96),\n        mode=(\"bilinear\", \"nearest\")\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image'].numpy()\nmedicai_label = output['label'].numpy()\n</code></pre>"},{"location":"transformations/manage-transformations/#scaleintensity-range","title":"ScaleIntensity Range","text":"<p>Scale the intensity of the entire array from the range <code>[a_min, a_max]</code> to <code>[b_min, b_max]</code>, with an optional clipping feature.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    ScaleIntensityRange,\n)\n\n# define transformations\ntransform = Compose([\n    ScaleIntensityRange(\n        keys=[\"image\"],\n        a_min=-175,\n        a_max=250,\n        b_min=0.0,\n        b_max=1.0,\n        clip=True,\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image'].numpy()\nmedicai_label = output['label']\n</code></pre>"},{"location":"transformations/manage-transformations/#crop-foreground","title":"Crop Foreground","text":"<p>Crop an image using a bounding box, where the bounding box is generated by selecting the foreground through the <code>select_fn</code> function at the specified channel_indices. A margin is added to each spatial dimension of the bounding box.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    CropForeground,\n)\n\n# define transformations\ntransform = Compose([\n    CropForeground(\n        keys=(\"image\", \"label\"), \n        source_key=\"image\"\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image']\nmedicai_label = output['label']\n</code></pre>"},{"location":"transformations/manage-transformations/#spacing","title":"Spacing","text":"<p>Resample input image into the specified pixdim. It will require <code>affine</code> meta information.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    Spacing,\n)\n\n# define transformations\ntransform = Compose([\n    Spacing(\n        keys=[\"image\", \"label\"], \n        pixdim=[2.0, 1.5, 1.5]\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image'].numpy()\nmedicai_label = output['label'].numpy()\n</code></pre>"},{"location":"transformations/manage-transformations/#orientation","title":"Orientation","text":"<p>Change the orientation of the input image to the specified one based on the provided <code>axcodes</code>. It will require <code>affine</code> meta information.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    Orientation,\n)\n\n# define transformations\ntransform = Compose([\n    Orientation(\n        keys=[\"image\", \"label\"], \n        axcodes=\"RAS\"\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image'].numpy()\nmedicai_label = output['label'].numpy()\n</code></pre>"},{"location":"transformations/manage-transformations/#random-rotate-90","title":"Random Rotate 90","text":"<p>Rotate the input sample 90 degree at random.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    RandRotate90,\n)\n\n# define transformations\ntransform = Compose([\n    RandRotate90(\n        keys=[\"image\", \"label\"], \n        prob=1.0, \n        max_k=3,\n        spatial_axes=(2,1)\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image'].numpy()\nmedicai_label = output['label'].numpy()\n</code></pre>"},{"location":"transformations/manage-transformations/#random-shift-intensity","title":"Random Shift Intensity","text":"<p>Randomly shift the intensity of the image by applying a randomly selected offset.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    RandShiftIntensity,\n)\n\n# define transformations\ntransform = Compose([\n    RandShiftIntensity(\n        keys=[\"image\"],\n        offsets=0.10,\n        prob=1\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image'].numpy()\nmedicai_label = output['label']\n</code></pre>"},{"location":"transformations/manage-transformations/#random-crop-by-positive-negative-label","title":"Random Crop By Positive Negative Label","text":"<p>Randomly crop fixed-sized regions from the image, with the center of each crop being either a foreground or background voxel based on the specified Positive-Negative Ratio. The function will return a list of arrays for all the cropped images.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    RandCropByPosNegLabel,\n)\n\n# define transformations\ntransform = Compose([\n    RandCropByPosNegLabel(\n        keys=[\"image\", \"label\"], \n        spatial_size=(96, 96, 96), \n        pos=1, \n        neg=1, \n        num_samples=1,\n        image_reference_key=\"image\",\n        image_threshold=0\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image'].numpy()\nmedicai_label = output['label']\n</code></pre>"},{"location":"transformations/manage-transformations/#random-spatial-crop","title":"Random Spatial Crop","text":"<p>Randomly crops a region of interest (ROI) with a specified size from the input tensors. This transform extracts a 3D spatial ROI from the tensors specified by <code>keys</code>. The size and center of the ROI can be either fixed or randomly determined within the bounds of the input tensor.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    RandSpatialCrop,\n)\n\n# define transformations\ntransform = Compose([\n    RandSpatialCrop(\n        keys=[\"image\", \"label\"],\n        roi_size=(96, 96, 96),\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image']\nmedicai_label = output['label']\n</code></pre>"},{"location":"transformations/manage-transformations/#random-flip","title":"Random Flip","text":"<p>Randomly flips tensors along specified spatial axes with a given probability. This transformation randomly decides whether to flip the input tensors based on the provided probability. If the decision is to flip, it reverses the tensor elements along the specified spatial axes.</p> <pre><code>from medicai.transforms import (\n    Compose,\n    RandFlip,\n)\n\n# define transformations\ntransform = Compose([\n    RandFlip(\n        keys=[\"image\", \"label\"],\n        spatial_axis=[0],\n        prob=1.0,\n    ),\n    RandFlip(\n        keys=[\"image\", \"label\"],\n        spatial_axis=[1],\n        prob=1.0,\n    ),\n    RandFlip(\n        keys=[\"image\", \"label\"],\n        spatial_axis=[2],\n        prob=1.0,\n    )\n])\n\n# load the raw data\ndata, meta = PyLoadImage(image_path=image_path, label_path=mask_path)\n\n# passing sample to medicai transform\noutput = transform(data, meta)\n\n# get transformed sample\nmedicai_image = output['image'].numpy()\nmedicai_label = output['label'].numpy()\n</code></pre>"}]}